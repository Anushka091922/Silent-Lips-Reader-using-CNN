# Silent-Lips-Reader-using-CNN
# Description:
Lip reading, the ability to understand spoken language by observing lip movements, is essential for individuals with hearing impairments and in scenarios where audio information is compromised. Automatic lip reading systems, powered by deep learning techniques, have shown promising results in converting lip movements into text. This project proposes an advanced lip reading model that combines 3D Convolutional Neural Networks (CNNs) and Gated Recurrent Units (GRUs) to improve the accuracy and robustness of lip reading.

The project's approach involves leveraging the spatiotemporal characteristics of lip motion using 3D CNNs. This allows the model to analyze sequential frames of lip movements and simultaneously capture spatial and temporal features. The GRU component is employed to learn long-term dependencies and capture temporal dynamics in the lip movement sequences.

# What to expect from the project:
The objective is to create a data-driven solution using a combination of 3D Convolutional Neural Networks (CNN) and Gated Recurrent Units (GRU) to accurately recognize speech from visual cues of lip movements captured in video data. The successful solution will provide an accurate and efficient silent speech recognition system that can interpret speech from visual cues of lip movements. It has the potential to revolutionize communication, accessibility, and human-machine interaction in various domains, making it a versatile technology with wide-ranging applications

# Technologies and Tools:

1)Artificial Intelligence

2)Deep learning

3)Machine Learning

4)Python

5)Flask

6)Web development

7) Advanced AI Models

8) IBM Watson Studio

# Referrences:
https://dl.acm.org/doi/fullHtml/10.1145/3411764.3445565
